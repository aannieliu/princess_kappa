{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Parse 2015 movies for prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import requests\n",
    "import json\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newmovies = pd.read_csv('new_movies.csv')\n",
    "#tts = (list(set(movies.imdbID)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tts = newmovies.imdb_id\n",
    "tts2 = []\n",
    "for t in tts:\n",
    "    if str(t)!='nan':\n",
    "        tts2.append(str(t))\n",
    "tts = tts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.7 s, sys: 1.17 s, total: 52.8 s\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "directorlist = []\n",
    "for t in tts:\n",
    "    url = \"http://www.imdb.com/title/{}/\".format(t)\n",
    "    t1970 = requests.get(url)\n",
    "    soup = BeautifulSoup(t1970.text, \"html.parser\")\n",
    "    tb = soup.find(\"table\").findAll(\"div\", attrs = {'class','txt-block'})\n",
    "    if tb[0].find('a')['href'] == None:\n",
    "        directorlist.append(None)\n",
    "    else:\n",
    "        directorlist.append(tb[0].find('a')['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#directorlist2 = dict(zip(tts, directorlist)) \n",
    "fd=open(\"directorlist2015.json\",\"w\")\n",
    "json.dump(directorlist, fd)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"directorlist2015.json\") as json_file:\n",
    "    directorlist = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "director_dict = {\"Name\":[], \"DOB\":[], \"Birthplace\":[], \"wins\":[], \"credits\":[]}\n",
    "\n",
    "for u in tqdm(directorlist, leave=True):\n",
    "    #print u\n",
    "    url = 'http://www.imdb.com{}'.format(u)\n",
    "    t1990=requests.get(url)\n",
    "    soup=BeautifulSoup(t1990.text, \"html.parser\")\n",
    "    try:\n",
    "        divs=soup.findAll('div', attrs = {'id':'name-born-info'})[0]\n",
    "        Name = soup.findAll('table', attrs = {'id':'name-overview-widget-layout'})[0].find('span',attrs={'class':'itemprop'}).get_text()\n",
    "        try: \n",
    "            DOB=divs.find('time').get('datetime')\n",
    "        except:\n",
    "            DOB=None \n",
    "        try:\n",
    "            Birthplace=divs.findAll('a')[-1].get_text()\n",
    "        except:\n",
    "            Birthplace=None\n",
    "        try:\n",
    "            wins=soup.findAll('div', attrs = {'class':'article highlighted'})[0].find_all('span')[0].get_text().strip()\n",
    "        except:\n",
    "            wins=0\n",
    "        try:\n",
    "            credits=soup.findAll('div', attrs = {'id':'filmo-head-director'})[0].get_text().strip()[22:24]\n",
    "        except:\n",
    "            credits=0\n",
    "        if Name not in director_dict[\"Name\"]:\n",
    "            director_dict[\"Name\"].append(Name)\n",
    "            director_dict['DOB'].append(DOB)\n",
    "            director_dict['Birthplace'].append(Birthplace)\n",
    "            director_dict['wins'].append(wins)\n",
    "            director_dict['credits'].append(credits)\n",
    "    except:\n",
    "        pass\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1961-1-1\n",
      "1970-1-1\n",
      "2015-11-23\n",
      "1972-1-1\n",
      "1959-1-1\n",
      "1952-1-1\n",
      "2015-11-23\n",
      "1967-1-1\n",
      "1968-1-1\n",
      "1957-1-1\n",
      "1968-1-1\n",
      "1974-1-1\n",
      "2015-11-23\n",
      "2015-11-23\n",
      "1972-1-1\n",
      "1965-1-1\n",
      "1977-1-1\n",
      "1973-1-1\n",
      "1972-1-1\n",
      "1979-1-1\n",
      "1972-1-1\n",
      "1965-1-1\n",
      "1966-1-1\n",
      "1963-1-1\n",
      "1968-1-1\n",
      "1973-1-1\n",
      "1971-1-1\n",
      "2015-11-23\n",
      "1970-1-1\n",
      "1964-1-1\n",
      "2015-11-23\n",
      "1976-1-1\n",
      "1972-1-1\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "directordf = pd.DataFrame(director_dict) ### fix 'XXXX-0-0' date issue\n",
    "for i in range(len(directordf.DOB)):\n",
    "    if directordf.DOB[i] == None:\n",
    "        directordf.DOB[i] = '2015-11-23'\n",
    "        print directordf.DOB[i]\n",
    "    if directordf.DOB[i].split('-')[1] == '0' or directordf.DOB[i].split('-')[2] == '0':\n",
    "        directordf.DOB[i] = directordf.DOB[i].split('-')[0]+'-1'+'-1'\n",
    "        print directordf.DOB[i]\n",
    "        \n",
    "today = datetime.datetime(2015, 11, 23)\n",
    "directordf['age'] = (today - directordf.DOB.apply(pd.datetools.parse)).values/np.timedelta64(1, 'D')/365.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directordf.to_csv('directordf2015.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [02:53<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.9 s, sys: 870 ms, total: 47.7 s\n",
      "Wall time: 2min 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "actorurl = {}\n",
    "### return a dict, with key the movie id and values the urls for actors \n",
    "for t in tqdm(tts, leave=True):\n",
    "    try:\n",
    "        actorurl[t] = []\n",
    "        l = []\n",
    "        url = \"http://www.imdb.com/title/{}/\".format(t)\n",
    "        t1970=requests.get(url)\n",
    "        soup = BeautifulSoup(t1970.text, \"html.parser\")\n",
    "        divs = soup.find('table').findAll('div', attrs = {'class':'txt-block', 'itemprop':'actors'})[0]\n",
    "        for div in divs.find_all('a'):\n",
    "            l.append(div.get('href'))\n",
    "        actorurl[t] = l[:-1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "fd=open(\"actorurl2015.json\",\"w\")\n",
    "json.dump(actorurl, fd)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"actorurl2015.json\") as json_file:\n",
    "    actorurl = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 304/304 [10:51<00:00,  0.53it/s]\n",
      "/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-11-23\n",
      "1993-1-1\n",
      "2015-11-23\n",
      "1968-1-1\n",
      "2015-11-23\n",
      "1985-1-1\n",
      "2015-11-23\n",
      "1986-1-1\n",
      "2015-11-23\n",
      "2015-11-23\n",
      "1947-1-1\n",
      "2015-11-23\n",
      "2015-11-23\n",
      "1963-1-1\n",
      "1963-1-1\n",
      "1990-1-1\n",
      "2015-11-23\n",
      "2015-11-23\n",
      "2015-11-23\n",
      "2015-11-23\n",
      "CPU times: user 3min 5s, sys: 3.44 s, total: 3min 8s\n",
      "Wall time: 10min 52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "actor_dict = {\"Name\":[], \"DOB\":[], \"Birthplace\":[], \"wins\":[], \"credits\":[]}\n",
    "\n",
    "for k in tqdm(actorurl.keys(), leave=True):\n",
    "    url_list = actorurl[k]\n",
    "    for u in url_list:\n",
    "        #print u\n",
    "        try:\n",
    "            url = 'http://www.imdb.com{}'.format(u)\n",
    "            t1990=requests.get(url)\n",
    "            soup=BeautifulSoup(t1990.text, \"html.parser\")\n",
    "            divs=soup.findAll('table', attrs = {'id':'name-overview-widget-layout'})[0].findAll('div', attrs = {'id':'name-born-info'})[0]\n",
    "            try:\n",
    "                Name=soup.findAll('table', attrs = {'id':'name-overview-widget-layout'})[0].find('span',attrs={'class':'itemprop'}).get_text()\n",
    "            except:\n",
    "                Name=None\n",
    "            try:\n",
    "                DOB=divs.find('time').get('datetime')\n",
    "            except:\n",
    "                DOB=None\n",
    "            try:\n",
    "                Birthplace=divs.findAll('a')[-1].get_text()\n",
    "            except:\n",
    "                Birthdplace=None\n",
    "            try:\n",
    "                wins=soup.findAll('div', attrs = {'class':'article highlighted'})[0].find_all('span')[0].get_text().strip()\n",
    "            except:\n",
    "                wins=0\n",
    "                \n",
    "            try:\n",
    "                c = soup.findAll('div', attrs = {'id':'filmo-head-actor'})[0]\n",
    "                c = str(c.get_text()[20:].strip())\n",
    "                credit = float(''.join(x for x in c if x.isdigit()))\n",
    "            except:\n",
    "                c = soup.findAll('div', attrs = {'id':'filmo-head-actress'})[0]\n",
    "                c = str(c.get_text()[20:].strip())\n",
    "                credit = float(''.join(x for x in c if x.isdigit()))\n",
    "                \n",
    "            if Name not in actor_dict[\"Name\"]:\n",
    "                actor_dict['Name'].append(Name)\n",
    "                actor_dict['DOB'].append(DOB)\n",
    "                actor_dict['Birthplace'].append(Birthplace)\n",
    "                actor_dict['wins'].append(wins)\n",
    "                actor_dict['credits'].append(credit)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "import datetime\n",
    "today = datetime.datetime(2015, 11, 23)\n",
    "actordf=pd.DataFrame(actor_dict)\n",
    "\n",
    "for i in range(len(actordf.DOB)):\n",
    "    if actordf.DOB[i] == None:\n",
    "        actordf.DOB[i] = '2015-11-23'\n",
    "        print actordf.DOB[i]\n",
    "    if actordf.DOB[i].split('-')[1] == '0' or actordf.DOB[i].split('-')[2] == '0':\n",
    "        actordf.DOB[i] = actordf.DOB[i].split('-')[0]+'-1'+'-1'\n",
    "        print actordf.DOB[i]\n",
    "    \n",
    "### calculate the age\n",
    "actordf['age'] = (today - actordf.DOB.apply(pd.datetools.parse)).values/np.timedelta64(1, 'D')/365.25\n",
    "actordf.to_csv('actordf2015.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
